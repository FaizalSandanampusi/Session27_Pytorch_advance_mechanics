{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "2a3d4d4d-cad0-4c54-8f4f-79ac49683382",
    "_uuid": "62a6894a-9c0b-4662-9b5b-c018e1c6073b",
    "collapsed": false,
    "id": "xtYj57XFr0Zd",
    "jupyter": {
     "outputs_hidden": false
    },
    "trusted": true
   },
   "source": [
    "# Step 1: Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "011a6e4b-58aa-4004-8d25-9e1264430549",
    "_uuid": "255cb91e-910c-4383-9248-df758f1c6785",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-02-02T05:05:16.016620Z",
     "iopub.status.busy": "2025-02-02T05:05:16.016305Z",
     "iopub.status.idle": "2025-02-02T05:05:16.020526Z",
     "shell.execute_reply": "2025-02-02T05:05:16.019712Z",
     "shell.execute_reply.started": "2025-02-02T05:05:16.016586Z"
    },
    "id": "VBRiP100rRbE",
    "jupyter": {
     "outputs_hidden": false
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "75219930-a070-4525-bd61-b6b95850c875",
    "_uuid": "1e1ec47c-64b1-45b9-a185-1ad9f622d60b",
    "collapsed": false,
    "id": "jl95vULurtxf",
    "jupyter": {
     "outputs_hidden": false
    },
    "trusted": true
   },
   "source": [
    "\n",
    "# Step 2: Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_cell_guid": "edb0a82b-ae02-4667-b08d-137fc9f687b0",
    "_uuid": "b4552154-40d0-44af-bfa0-98257da6f740",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-02-02T05:05:19.412467Z",
     "iopub.status.busy": "2025-02-02T05:05:19.412200Z",
     "iopub.status.idle": "2025-02-02T05:05:19.479823Z",
     "shell.execute_reply": "2025-02-02T05:05:19.479126Z",
     "shell.execute_reply.started": "2025-02-02T05:05:19.412446Z"
    },
    "id": "nVS6iLQErrCG",
    "jupyter": {
     "outputs_hidden": false
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Transform: convert images to tensors and normalize\n",
    "transform = transforms.Compose([transforms.ToTensor(), transforms.Lambda(lambda x: x.view(-1))])\n",
    "\n",
    "# Load MNIST data\n",
    "train_dataset = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
    "test_dataset = datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n",
    "\n",
    "# DataLoader\n",
    "batch_size = 32\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "19986de7-00cb-47c5-9b5d-2f63389d6dce",
    "_uuid": "bd16995b-72f5-4ffa-9b81-fb064020e751",
    "collapsed": false,
    "id": "d1C4wnJKsBWA",
    "jupyter": {
     "outputs_hidden": false
    },
    "trusted": true
   },
   "source": [
    "# Step 3: Custom Components"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "eb97e90b-c238-43f7-8969-7491e779db83",
    "_uuid": "0c897da0-a41b-41b2-825b-23857f953d43",
    "collapsed": false,
    "id": "AW34vRfNz2CA",
    "jupyter": {
     "outputs_hidden": false
    },
    "trusted": true
   },
   "source": [
    "## Linear Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "72b60b0e-dda0-4851-b662-1b1d2dda0473",
    "_uuid": "a1be3f78-170a-471f-af22-3d19649f8b3a",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-02-02T05:05:25.478342Z",
     "iopub.status.busy": "2025-02-02T05:05:25.478063Z",
     "iopub.status.idle": "2025-02-02T05:05:25.492272Z",
     "shell.execute_reply": "2025-02-02T05:05:25.491422Z",
     "shell.execute_reply.started": "2025-02-02T05:05:25.478320Z"
    },
    "id": "hkAmH32HvT7T",
    "jupyter": {
     "outputs_hidden": false
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class CustomLinear(nn.Module):\n",
    "    def __init__(self, in_features, out_features):\n",
    "        super(CustomLinear, self).__init__()\n",
    "        self.W = nn.Parameter(torch.randn(in_features, out_features) * (2 / in_features)**0.5)\n",
    "        self.b = nn.Parameter(torch.zeros(out_features))\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x @ self.W + self.b\n",
    "\n",
    "class MultiHeadSelfAttention(nn.Module):\n",
    "    def __init__(self, embed_dim, num_heads):\n",
    "        super(MultiHeadSelfAttention, self).__init__()\n",
    "        assert embed_dim % num_heads == 0, \n",
    "        self.num_heads = num_heads\n",
    "        self.head_dim = embed_dim // num_heads\n",
    "\n",
    "        self.query_weights = CustomLinear(embed_dim, embed_dim)\n",
    "        self.key_weights = CustomLinear(embed_dim, embed_dim)\n",
    "        self.value_weights = CustomLinear(embed_dim, embed_dim)\n",
    "        self.output_weights = CustomLinear(embed_dim, embed_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch_size, seq_len, embed_dim = x.shape\n",
    "\n",
    "        # Compute Q, K, V\n",
    "        Q = self.query_weights(x)\n",
    "        K = self.key_weights(x)\n",
    "        V = self.value_weights(x)\n",
    "\n",
    "        # Reshape for multi-head attention\n",
    "        Q = Q.view(batch_size, seq_len, self.num_heads, self.head_dim).transpose(1, 2)\n",
    "        K = K.view(batch_size, seq_len, self.num_heads, self.head_dim).transpose(1, 2)\n",
    "        V = V.view(batch_size, seq_len, self.num_heads, self.head_dim).transpose(1, 2)\n",
    "\n",
    "        # Scaled dot-product attention\n",
    "        scores = Q @ K.transpose(-2, -1) / (self.head_dim ** 0.5)\n",
    "        attention_weights = F.softmax(scores, dim=-1)\n",
    "        attention_output = attention_weights @ V\n",
    "\n",
    "        # Concatenate heads and apply output projection\n",
    "        attention_output = attention_output.transpose(1, 2).contiguous().view(batch_size, seq_len, embed_dim)\n",
    "        return self.output_weights(attention_output)\n",
    "\n",
    "class CustomReLU(nn.Module):\n",
    "    def forward(self, x):\n",
    "        return torch.maximum(x, torch.zeros_like(x))\n",
    "\n",
    "class CustomLayerNorm(nn.Module):\n",
    "    def __init__(self, normalized_shape, epsilon=1e-5):\n",
    "        super(CustomLayerNorm, self).__init__()\n",
    "        self.gamma = nn.Parameter(torch.ones(normalized_shape))\n",
    "        self.beta = nn.Parameter(torch.zeros(normalized_shape))\n",
    "        self.epsilon = epsilon\n",
    "\n",
    "    def forward(self, x):\n",
    "        mean = x.mean(dim=-1, keepdim=True)\n",
    "        variance = ((x - mean) ** 2).mean(dim=-1, keepdim=True)\n",
    "        x_normalized = (x - mean) / torch.sqrt(variance + self.epsilon)\n",
    "        return self.gamma * x_normalized + self.beta\n",
    "\n",
    "class CustomCrossEntropyLoss(nn.Module):\n",
    "    def forward(self, outputs, targets):\n",
    "        # Compute softmax\n",
    "        exp_logits = torch.exp(outputs - torch.max(outputs, dim=1, keepdim=True).values)\n",
    "        probs = exp_logits / torch.sum(exp_logits, dim=1, keepdim=True)\n",
    "\n",
    "        # Negative log likelihood loss\n",
    "        target_probs = probs[range(len(targets)), targets]\n",
    "        loss = -torch.log(target_probs + 1e-12)  # Avoid log(0)\n",
    "        return loss.mean()\n",
    "\n",
    "class CustomFeedForward(nn.Module):\n",
    "    def __init__(self, embed_dim, hidden_dim):\n",
    "        super(CustomFeedForward, self).__init__()\n",
    "        self.linear1 = CustomLinear(embed_dim, hidden_dim)\n",
    "        self.activation = CustomReLU()\n",
    "        self.linear2 = CustomLinear(hidden_dim, embed_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.linear1(x)\n",
    "        x = self.activation(x)\n",
    "        x = self.linear2(x)\n",
    "        return x\n",
    "\n",
    "class CustomMeanPooling(nn.Module):\n",
    "    def forward(self, x):\n",
    "        return x.mean(dim=1)\n",
    "\n",
    "# Define Transformer ecoder layer\n",
    "class TransformerEncoderLayer(nn.Module):\n",
    "    def __init__(self, embed_dim, num_heads):\n",
    "        super(TransformerEncoderLayer, self).__init__()\n",
    "        self.self_attention = MultiHeadSelfAttention(embed_dim, num_heads)\n",
    "        self.norm1 = CustomLayerNorm(embed_dim)\n",
    "        self.norm2 = CustomLayerNorm(embed_dim)\n",
    "        self.feedforward = CustomFeedForward(embed_dim, embed_dim * 4)\n",
    "\n",
    "    def forward(self, x):\n",
    "        attention_output = self.self_attention(x)\n",
    "        x = x + attention_output\n",
    "        x = self.norm1(x)\n",
    "\n",
    "        feedforward_output = self.feedforward(x)\n",
    "        x = x + feedforward_output\n",
    "        x = self.norm2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "68fa01d8-3940-4ddd-8b9b-eab38feb0622",
    "_uuid": "a5ecd323-c03b-432b-ad62-947c327f3a49",
    "collapsed": false,
    "id": "qPTEwFHeyd4a",
    "jupyter": {
     "outputs_hidden": false
    },
    "trusted": true
   },
   "source": [
    "## Define Custom Transformer Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "4f7006fe-9f17-41c1-b7aa-a548580b69e8",
    "_uuid": "ccebbc9f-e612-44b6-a11e-5575d42717fe",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-02-02T05:05:32.326716Z",
     "iopub.status.busy": "2025-02-02T05:05:32.326440Z",
     "iopub.status.idle": "2025-02-02T05:05:32.332137Z",
     "shell.execute_reply": "2025-02-02T05:05:32.331335Z",
     "shell.execute_reply.started": "2025-02-02T05:05:32.326693Z"
    },
    "id": "DU82jdNLydYy",
    "jupyter": {
     "outputs_hidden": false
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class CustomTransformerModel(nn.Module):\n",
    "    def __init__(self, input_dim, embed_dim, num_heads, num_layers, num_classes):\n",
    "        super(CustomTransformerModel, self).__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.embed_dim = embed_dim\n",
    "\n",
    "        # Custom Linear layer for embedding projection\n",
    "        self.embed = CustomLinear(input_dim, embed_dim)\n",
    "\n",
    "        # Transformer Encoder Layers\n",
    "        self.layers = nn.ModuleList([\n",
    "            TransformerEncoderLayer(embed_dim, num_heads)\n",
    "            for _ in range(num_layers)\n",
    "        ])\n",
    "\n",
    "        # Final Pooling and Fully Connected Layer\n",
    "        self.pooling = CustomMeanPooling()\n",
    "        self.fc = CustomLinear(embed_dim, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Embedding\n",
    "        x = self.embed(x)\n",
    "\n",
    "        # Apply Transformer Encoder Layers\n",
    "        for layer in self.layers:\n",
    "            x = layer(x)\n",
    "\n",
    "        # Pooling\n",
    "        x = self.pooling(x)\n",
    "\n",
    "        # Final Classification Layer\n",
    "        x = self.fc(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "9805670f-9231-40fe-886a-b91355b7a487",
    "_uuid": "1fdf9f7c-e9f1-4332-8527-b920b767ffc5",
    "collapsed": false,
    "id": "4RGSEoW60ExT",
    "jupyter": {
     "outputs_hidden": false
    },
    "trusted": true
   },
   "source": [
    "## Initialize Model, Loss, and Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "9f8057a4-048c-44e3-99b6-93e8c0098261",
    "_uuid": "f726855f-951a-439e-8c49-4022eb6db379",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-02-02T05:05:35.613124Z",
     "iopub.status.busy": "2025-02-02T05:05:35.612828Z",
     "iopub.status.idle": "2025-02-02T05:05:35.622759Z",
     "shell.execute_reply": "2025-02-02T05:05:35.621900Z",
     "shell.execute_reply.started": "2025-02-02T05:05:35.613100Z"
    },
    "id": "HCa-1Js90GeM",
    "jupyter": {
     "outputs_hidden": false
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "model = CustomTransformerModel(input_dim=28, embed_dim=128, num_heads=8, num_layers=2, num_classes=10)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "c900cd21-198f-4b99-b756-90b63ec9b17c",
    "_uuid": "12e2ae09-08b4-4561-ba85-2e9b5c3f932e",
    "collapsed": false,
    "id": "83ayRj4Q0RaJ",
    "jupyter": {
     "outputs_hidden": false
    },
    "trusted": true
   },
   "source": [
    "# Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "6144d663-b52b-4f6a-b622-7f9782d55881",
    "_uuid": "259f8ff4-484d-4735-92f7-d28157cc6f31",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-02-02T05:06:11.736021Z",
     "iopub.status.busy": "2025-02-02T05:06:11.735669Z",
     "iopub.status.idle": "2025-02-02T05:14:48.758162Z",
     "shell.execute_reply": "2025-02-02T05:14:48.757269Z",
     "shell.execute_reply.started": "2025-02-02T05:06:11.735991Z"
    },
    "id": "UJqy85J10VwW",
    "jupyter": {
     "outputs_hidden": false
    },
    "outputId": "3d13ebc4-d940-4d6e-a53e-46e18e2e1171",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "for epoch in range(10):  # Train for 5 epochs\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for images, labels in tqdm(train_loader):\n",
    "        # Reshape for sequence processing\n",
    "        images = images.view(images.size(0), 28, 28)  # [batch_size, seq_len, embed_dim]\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        # Accuracy calculation during training\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "    accuracy = 100 * correct / total\n",
    "    print(f'Epoch {epoch + 1}, Loss: {total_loss / len(train_loader):.4f}, Accuracy: {accuracy:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "acce6372-0bea-4d13-a9a5-24fbbab14919",
    "_uuid": "9535a9f9-2001-4795-bf7c-6cf5a7101d39",
    "collapsed": false,
    "id": "rSO45DpR2tam",
    "jupyter": {
     "outputs_hidden": false
    },
    "trusted": true
   },
   "source": [
    "## Evaluation Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "eef3fa60-a985-4c6a-98a0-45367d63b35b",
    "_uuid": "56f11ba2-a742-4251-a483-6623a70d458d",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-02-02T05:15:15.869075Z",
     "iopub.status.busy": "2025-02-02T05:15:15.868799Z",
     "iopub.status.idle": "2025-02-02T05:15:19.520505Z",
     "shell.execute_reply": "2025-02-02T05:15:19.519553Z",
     "shell.execute_reply.started": "2025-02-02T05:15:15.869055Z"
    },
    "id": "sCRvF9RB2sj7",
    "jupyter": {
     "outputs_hidden": false
    },
    "outputId": "6508c999-3d5f-4325-c0e2-1b347cde8747",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        images = images.view(images.size(0), 28, 28)  # [batch_size, seq_len, embed_dim]\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print(f'Test Accuracy: {100 * correct / total:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "83c9e8fc-569e-419b-b311-cbebe0e26cdd",
    "_uuid": "fff2449a-469c-415c-87f3-802aaa1f15c7",
    "collapsed": false,
    "id": "4OWLH00Ev9km",
    "jupyter": {
     "outputs_hidden": false
    },
    "trusted": true
   },
   "source": [
    "#Step 7: Visualizing Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "be8dcab0-3e0c-4ede-8049-040b334d01c0",
    "_uuid": "585b13fe-0925-4630-ac95-6cb5fa24825c",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-02-02T05:15:19.521962Z",
     "iopub.status.busy": "2025-02-02T05:15:19.521680Z",
     "iopub.status.idle": "2025-02-02T05:15:20.226155Z",
     "shell.execute_reply": "2025-02-02T05:15:20.225100Z",
     "shell.execute_reply.started": "2025-02-02T05:15:19.521940Z"
    },
    "id": "ysBXsPrev6vp",
    "jupyter": {
     "outputs_hidden": false
    },
    "outputId": "e9b7fc47-cd10-4d92-cebf-c176cc3b2ce1",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Function to visualize predictions\n",
    "def visualize_predictions(model, data_loader):\n",
    "    model.eval()\n",
    "    images, labels = next(iter(data_loader))\n",
    "    images = images.view(images.size(0), 28, 28)  # Reshape to [batch_size, seq_len, embed_dim]\n",
    "\n",
    "    # Get predictions\n",
    "    outputs = model(images)\n",
    "    _, predictions = torch.max(outputs.data, 1)\n",
    "\n",
    "    # Plot the first 10 images and their predictions in a 2x5 grid\n",
    "    fig, axes = plt.subplots(2, 5, figsize=(15, 6))\n",
    "    axes = axes.flatten()  # Flatten the 2D array of axes to make indexing easier\n",
    "\n",
    "    for i in range(10):\n",
    "        ax = axes[i]\n",
    "        ax.imshow(images[i].view(28, 28).cpu().numpy(), cmap='gray')\n",
    "        ax.set_title(f'Pred: {predictions[i].item()}\\nTrue: {labels[i].item()}')\n",
    "        ax.axis('off')\n",
    "\n",
    "    plt.tight_layout()  # Adjust layout to prevent overlap\n",
    "    plt.show()\n",
    "\n",
    "# Visualize predictions on the test set\n",
    "visualize_predictions(model, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "2e6abace-369c-41a0-939e-95acc31a1913",
    "_uuid": "f27f0659-5989-4fdf-892f-7593422e6203",
    "collapsed": false,
    "id": "DCPryA1swp6I",
    "jupyter": {
     "outputs_hidden": false
    },
    "trusted": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [],
   "dockerImageVersionId": 30840,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
